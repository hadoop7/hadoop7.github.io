<!DOCTYPE html>
<html lang="en">

<meta http-equiv="content-type" content="text/html;charset=utf-8" />

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!--<link rel="shortcut icon" type="image/png" href="../assets/images/favicon.png" />-->
  <link rel="canonical" href="introduction.html" />

  <title>Hadoop | Installation</title>
  <meta name="description" content="&lt;p&gt;Hadoop
&lt;/p&gt;">
  <meta name="author" content="sai sri vastava">
  <meta property="og:image" content="../assets/images/poster.png" />
  <meta property="og:title" content="Hadoop | Introduction" />
  <meta property="og:site_name" content="Hadoop | Introduction" />
  <meta property="og:url" content="installation.html" />
  <meta property="og:type" content="website" />
  <meta property="og:description" content="&lt;p&gt;Hadoop
&lt;/p&gt;" />

  <!-- CSS -->
  <link rel="stylesheet" media="screen" href="../assets/stylesheets/main.css" />
  <!-- Font-Awesome -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->

  <!-- CSS -->
  <link rel="stylesheet" media="screen" href="../assets/lib/highlightjs/styles/atelier-savanna-dark.css" />
</head>

<body data-library="std_lib" data-section="asserts">
  <header class="navbar navbar-inverse navbar-fixed-top" style="background-color: #26525B ;" role="navigation">
    <div class="container-fluid">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        <a href="../index.html" class="navbar-brand">
          <!-- <img src=../assets/images/navbar_brand_light.svg alt=""> -->
          <span>Hadoop7</span>
        </a>
      </div>

      <div id="navbar-sections" class="collapse navbar-collapse">
        <ul class="nav navbar-nav navbar-right">


          <li class="actives  current ">
            <span class="bullet-active"></span>
            <a href="introduction.html" style="color: #26525B; font-weight: bold;">Installing Hadoop in Ubuntu </a>
          </li>


          <li class="actives ">
            <span class="bullet-active"></span>
            <a href="installing.html">Installing hadoop</a>
          </li>


          <li class="actives ">
            <span class="bullet-active"></span>
            <a href="executingmapreduce.html">Executing mapreduce programs in hadoop  </a>
          </li>


          <li class="actives ">
            <span class="bullet-active"></span>
            <a href="mapreduceprograms.html">Objects</a>
          </li>

        </ul>
      </div>
      <!--.nav-collapse -->
    </div>
  </header>
  <div id="wrapper">

    <section id="sidebar">
      <div class="header-technologie">
        <div class="content-logo-technologie" style="background-color: #26525B;">
          <img src="assets/images/hadoop.png" />
        </div>
        <h1 class="text-center">HADOOP</h1>
      </div>

      <ul>
        <li>
          <h3>Sections</h3>
        </li>


        <li class="actives  current ">
          <span class="bullet-active"></span>
          <a href="index.html" style="color: #26525B; font-weight: bold;">  Introduction </a>
        </li>

        <li class="actives ">
          <span class="bullet-active"></span>
          <a href="installation.html">Installing hadoop  </a>
        </li>


        <li class="actives ">
          <span class="bullet-active"></span>
          <a href="executingmapreduce.html">Executing mapreduce programs  </a>
        </li>

        <li class="actives ">
          <span class="bullet-active"></span>
          <a href="mapreduceprograms.html">Mapreduce programs</a>
        </li>

      </ul>
    </section>

    <section id="content-detail">
      <div class="container-fluid">
        <div class="row">
          <div class="col-lg-12">

            <div class="content-header clearfix">
              <h2 class="pull-left">Installing Hadoop in Ubuntu</h2>
              <div class="add-exercises pull-right hidden-xs">

              </div>
            </div>

            <div class="exercises-wrapper">
              <h3>Hadoop</h3>
              <p>               Hadoop is an open source, Java-based programming framework that supports the processing and storage of extremely large data sets in a distributed computing environment. It is part of the <a href="https://www.apache.org/">Apache</a>                project sponsored by the Apache Software Foundation.</p>
              Hadoop needs Java to be installed in the system. If you dont have java installed in the system, follow from this step , or if you hav java installed in your system, you cvan skip this step.
              <h3>Installing java</h3>
              <p> Check the java installation in your system by typing " <code>java -version</code> " in a terminal. It will display the installed java details .</p>
              <img src="/assets/images/hadoop/java-version-min.png" alt="java-version.png" width="732" height="438" />
              <br>
              <br>
              <p>If java is not installed, then install java using the command</p>
              <pre>sudo apt install openjdk-8-jdk-headless</pre>
              <h3>Setting JAVA_HOME path</h3>
              <p> In <em>.bashrc</em> we have to add JAVA_HOME (the address for java installation ) .

                <p> Find the location where your java is installed. For that go to <em>/usr/lib/jvm/ </em> folder.
                  <pre>cd /usr/lib/jvm/</pre> and then run
                  <pre>ls</pre>
                </p>
                <img src="/assets/images/hadoop/java-loc-min.png" width="732" height="438" /><br>
                <br><br>
                <p>After locating the java installation path, we have to set the JAVA_HOME in <strong><em> .bashrc </em></strong>. Now, open <strong><em> .bashrc </em></strong> file using any editor like <em>gedit</em> or <em>nano</em>. Here im using <em>gedit</em>                  .
                </p><pre>sudo gedit ~/.bashrc</pre>
                <p> Now, assign the java installation location to JAVA_HOME as follows. </p>
                <pre>export JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64"</pre> Now, to apply the changes, we have to  update <strong> <em>.bashrc</em></strong> .For that run
                <pre>source ~/.bashrc</pre> Now, do the same in <em>/etc/environment</em>  file using the command
                <pre>sudo gedit /etc/environment </pre> and add the JAVA_HOME here also. And update the <strong><em>/etc/environment </em></strong> file by running
                <pre>source /etc/environment</pre>
                <img src="/assets/images/hadoop/java-home-min.png" width="732" height="438" />
                <br><br>
                <p>Verify JAVA_HOME by running the command</p>
                <pre>echo $JAVA_HOME</pre>
                <p>If everything is correct , it will display the JAVA_HOME location.</p>
                <img src="/assets/images/hadoop/echo-java-home-min.png" width="732" height="438" />

                <br><br>
                <h3>Configuring ssh</h3> For installing hadoop , we have to configure ssh. First, install ssh by running the command
                <pre>sudo apt install ssh</pre> Next, open a terminal and run the following command.
                <pre>ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa</pre>
                <p>It will generate a rsa key, like below.</p>

                <img src="/assets/images/hadoop/ssh-min.png" width="732" height="438" />
                <br><br>
                <p>Now, we have to add that key to authorized keys using the following command.</p>
                <pre>cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys</pre> To check the ssh, run <code> ssh localhost </code> .It must login without asking any password. If it asks for password, then you have to repeat the above ssh configuration steps.

                <h3>Installing Hadoop in Pseudo Distributed Mode</h3> Download hadoop-2.7.3 from this <a href="http://apache.mesi.com.ar/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz">link</a>. After downloading, extract it to the folder where you want to install hadoop. I am installing it in <strong><em>/usr/local/hadoop</em></strong>                location.  So after extracting the hadoop jar, run the below command to copy it to <strong><em>/usr/local/hadoop</em></strong>
                <pre>sudo mv hadoop-2.7.3 /usr/local/hadoop</pre>
                <h4>Step I: Setting up Hadoop</h4> We have to set <strong><em>HADOOP_HOME</strong></em> path . For that open terminal and edit the <strong><em> .bashrc </strong></em>file.
                <pre>sudo gedit .bashrc</pre> add the following lines
                <pre>export HADOOP_HOME=/usr/local/hadoop</pre>
                <pre>export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</pre>
                <p>refresh the <strong><em>.bashrc</strong></em> file</p>
                <pre>source .bashrc</pre>
                <img src="/assets/images/hadoop/hadoop-home-min.png" width="732" height="438" />
                <br><br>
                <h4>Step II: Hadoop Configuration</h4>
                <h5>Adding HADOOP_PREFIX</h5> Previously, we set JAVA_HOME path. Similarly, we have to set HADOOP_PREFIX path in <strong>hadoop-env.sh  </strong>. file present in<strong><em> etc/hadoop</em> </strong>folder . This is to specify the path for our hadoop folder.  To
                do that, open a terminal and run the following commands.
                <pre>cd /usr/local/hadoop/etc/hadoop</pre>
                <pre>gedit hadoop-env.sh</pre> and, in that file, add the HADOOP_PREFIX path
                <pre>export HADOOP_PREFIX=/usr/local/hadoop</pre>

                <h4>Configuring  <strong>core-site.xml </strong> file</h4>
                <p>Open <strong>core-site.xml</strong> file , which is located in "<strong><em> hadoop/etc/hadoop</em> </strong>" and add the following lines.</p>
                <pre>cd /usr/local/hadoop/etc/hadoop</pre>
                <pre>gedit core-site.xml</pre>
                <pre><textarea rows = "8" cols="150" readonly="readonly">

                <configuration>
               	  <property>
               		   <name>fs.defaultFS</name>
               		    <value>hdfs://localhost:9000</value>
               	    </property>
                </configuration>
              </textarea></pre>

                <h4>Configuring <strong>hdfs-site.xml</strong> file</h4> Open <em><strong>hdfs-site.xml</strong> </em>file , which is located in <strong>/etc/hadoop</strong> and add the following lines. Specify the path where you want to store the dfs data in <strong><em>"dfs.name.dir"</em></strong> and <strong><em>"dfs.data.dir"</em></strong>                property
                <pre>gedit hdfs-site.xml</pre>
                <pre><textarea rows = "15" cols="150" readonly="readonly">

               <configuration>
              	  <property>
                		    <name>dfs.name.dir</name>
                		    <value>file:///home/USERNAME/pseudo/dfs/name</value>
              	  </property>
              	  <property>
                		    <name>dfs.data.dir</name>
                		    <value>file:///home/USERNAME/pseudo/dfs/data</value>
              	  </property>
              	  <property>
                 		    <name>dfs.replication</name>
                  		  <value>1</value>
              	  </property>
              </configuration></textarea></pre>

                <h4>Configuring <strong>mapred-site.xml</strong> file</h4>
                <p>Open <em><strong>mapred-site.xml</strong></em> file (create if not present ), which is located in <strong>/etc/hadoop</strong> and add the following lines.
                </p>
                <pre>gedit mapred-site.xml</pre>
                <pre><textarea rows = "8" cols="150" readonly="readonly">

                <configuration>
               	  <property>
               		   <name>mapreduce.framework.name</name>
               		    <value>yarn</value>
               	  </property>
               </configuration></textarea></pre>

                <h4>Configuring <strong>yarn-site.xml</strong> file</h4>
                <p>Open <em><strong>yarn-site.xml </strong></em>file , which is located in <strong>/etc/hadoop</strong> and add the following lines.</p>
                <pre>gedit yarn-site.xml</pre>
                <pre><textarea rows = "12" cols="150" readonly="readonly">

                  <configuration>
               	      <property>
               		       <name>yarn.resourcemanager.hostname</name>
               		       <value>localhost</value>
               	      </property>
               	      <property>
               		       <name>yarn.nodemanager.aux-services</name>
               		       <value>mapreduce_shuffle</value>
               	      </property>
                </configuration></textarea></pre>

                <h3>Running hadoop</h3>
                <p>To start hadoop, first we have to format the namenode. For that change directory to <em>hadoop installation </em> directory and run the command
                  <pre>hdfs namenode –format</pre> If everything is correct it will show the following screen. (dont worry if your screen dont match this ).</p>

                <img src="/assets/images/hadoop/hadoop-format-min.png" width="732" height="438" />
                <br><br>
                <p>Now, after formatting namenode, we have to start namenode and datanode</p>
                For that run the command.
                <pre>start-dfs.sh</pre>
                <p>Then to check whether namenode and datanode are running or not, run<code> jps </code>. It will list all the java processes running in the system. You can notice that<em> namenode</em>, <em>datanode</em> and <em>secondarynamenode</em> are
                  running.
                </p>

                <img src="/assets/images/hadoop/jps-min.png" width="732" height="438" />
                <br><br>
                <p> Now, we have to start yarn. To do that, run</p>
                <pre>start-yarn.sh</pre>
                <p>You will get a screen like this. You can observe that resourceManager and NodeManager are also running.</p>

                <img src="/assets/images/hadoop/jps2-min.png" width="732" height="438" />
                <br><br>
                <p>Thats it...<strong>.Our installation is completed</strong>... :) Now, open your browser and run <code> http://localhost:50070 </code> to know about your namenodes and datanodes. You will get  a screen like this.</p>

                <img src="/assets/images/hadoop/dfs-browser-min.png" width="732" height="438" />
                <br><br>
                <p> Now,  in another tab, run <code> http://localhost:8088 </code> to manage your cluster.</p>

                <img src="/assets/images/hadoop/yarn-browser-min.png" width="732" height="438" />
                <br>
                <p>If you want to stop hadoop, then type and run</p>
                <pre>stop-dfs.sh</pre>
                <pre>stop-yarn.sh</pre> Or , simply you can run
                <pre>stop-all.sh</pre> And, each time you dont need to format the namenode. Just start dfs and yarn using the  above specified commands or, simply running
                <pre>start-all.sh</pre> To execute mapreduce program in hadoop, follow the<strong><a href="https://hadoop7.github.io/hadoop/executingmapreduce.html/"> link</a>.</strong>

            </div>
          </div>
        </div>

    </section>

    <footer id="bottom" class="light">
      <div class="container-fluid">
        <div class="col-md-12">
          <!-- <img src=../assets/images/footer_brand_dark.svg alt=""> -->

          <p><span>Hadoop7 is a website by Sai sri vastava Guntupalli</span></p>

        </div>
      </div>
    </footer>

    </div>
    <script>
      (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
          (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
          m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
      })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

      ga('create', 'UA-99000023-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- 
    <script src="../assets/lib/highlightjs/highlight.min.js" type="text/javascript"></script>
    <script src="../assets/lib/highlightjs/languages/scala.min.js" type="text/javascript"></script>
    <script src="../assets/javascripts/emojify-cdn.js"></script>
    <script src="../javascriptRoutes" type="text/javascript"></script>
    <script src="../assets/client-jsdeps.min.js" type="text/javascript"></script>
    <script src="../assets/client-opt.js" type="text/javascript"></script> -->

</body>

</html>
